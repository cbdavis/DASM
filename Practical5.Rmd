---
title: "Practical 5"
author: "Chris Davis"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    html_document:
        toc: true
        number_sections: true
---


```{r, message=FALSE, echo=FALSE}
library(ggplot2)
library(dplyr)
```

# Monte Carlo simulation 

## Quick review

We have a function $x = f(u,v)$ where:

* $u$ has uncertainty $s_u$
* $v$ has uncertainty $s_v$

We then:

* Construct a normal distribution $f_{n,u}$ using the mean found for $u$ and a standard deviation $s_u$ 
* Construct a normal distribution $f_{n,v}$ using the mean found for $v$ and a standard deviation $s_v$
* Take a random value $u_1$ from  fn,u and $v_1$ from fn,v  and calculate $x_1 = f(u_1, v_1)$
* Repeat n times
* Take average (or median) of all $x_i$ for (i = 1, ... n) 

## Example

Assume that for a research project you are told to calculate the uncertainty for the following formula:

$$f(p,q) = \frac{p \cdot q}{p + q}$$

For both $p$ and $q$ we have evidence of the following means and standard deviations:

* $p$: $\mu = 2$ and $\sigma = 0.5$
* $q$: $\mu = 5$ and $\sigma = 1$

We assume that the uncertainties for $p$ and $q$ follow normal distributions

```{r}
# take n samples
n <- 1000
# take n samples from normal distributions with different means and standard deviations
p <- rnorm(n, mean = 2, sd = 0.5)
q <- rnorm(n, mean = 5, sd = 1)
```

Calculate values for $f(p,q) = \frac{p \cdot q}{p + q}$
```{r}
f <- p*q/(p+q)
```

Plot the histogram, using 100 bins (use `breaks=100`)
```{r}
hist(f, breaks=100)
```

We now calculate the mean:
```{r}
f_bar <- mean(f)
f_bar
```

and then calculate the standard deviation:
```{r}
sig <- sd(f)
sig
```

Below we can see how both the mean and the standard deviation converge on a single value as we increase the number of samples from the distributions we defined for $p$ and $q$ (see page 33,34 of Lecture 7 for more explanation).  Note the log scale for the x axis.

```{r, echo=FALSE}
numSamples = 3000
f_bars = c()
sds = c()
for (n in seq(numSamples)){
  set.seed(1234)
  p <- rnorm(n, mean = 2, sd = 0.5)
  q <- rnorm(n, mean = 5, sd = 1)
  f <- p*q/(p+q)
  f_bars = c(f_bars, mean(f))
  sds = c(sds, sd(f))
}

df = data.frame(x=c(c(1:numSamples), c(1:numSamples)),
                y = f_bars, sds, 
                type = c(rep("Mean", numSamples), 
                         rep("Standard Deviation", numSamples)))

ggplot(df, aes(x, y)) + geom_line() + facet_wrap(~type) + 
  xlab("sample") + ylab("value") + 
  ggtitle("Values for Mean and SD with Increasing Numbers of Samples") + scale_x_log10()
```


## Exercise

Now you've been given a different formula: 

$$f(u,v) = u^2 + u + v$$

...and you've been told to perform a monte carlo simulation with 10000 samples this time.  We again assume that the variables `u` and `v` are normally distributed with the following means and standard deviations:

* $u$: $\mu = 1.2$ and $\sigma = 3$
* $v$: $\mu = 5$ and $\sigma = 1.7$

Now try to recreate the following results on your own.
 
Plot the histogram of $x = f(u,v) = u^2 + u + v$

```{r, echo=FALSE}
n <- 10000
# take n samples from normal distributions with different means and standard deviations
u <- rnorm(n, mean = 1.2, sd = 3)
v <- rnorm(n, mean = 5, sd = 1.7)
# calculate f(p,q)
f <- (u^2 + u + v)
hist(f, breaks=100)
```

Calculate mean(x) and std(x) for $x = f(u,v)$

```{r, echo=FALSE}
# calculate the mean
f_bar <- mean(f)
f_bar
# calculate the standard deviation
sig <- sd(f)
sig
```

# Working with Real Data Sets

## Example

For this example, you'll need a csv file.  To get it, **right click** on this link: [Guerry.csv](https://raw.githubusercontent.com/cbdavis/DASM/master/data/Guerry.csv) and select **"Save Target As"** or **"Save Link As"** to save it to your computer.

Internet Explorer might try to save this as "Guerry.**txt**", make sure to save this as "Guerry.**csv**" or adjust your code so that it knows to read the correct file.

One thing you need to check is your working directory. This is the directory where R looks for any files.  You can set this in RStudio `Session` -> `Set Working Directory` -> `Choose Directory`

<center><img src="./images/RStudioSetWorkingDirectory.png" style="border:2px solid black"></center>

Once you've done all this, you can now read in the data file: 
```{r, eval=FALSE}
data1 <- read.csv(file ="Guerry.csv")
```

```{r, echo=FALSE}
data1 <- read.csv(file ="./data/Guerry.csv")
```

Note that every time you read in a .csv file you will have a data frame, even if there is only a single column present.

As mentioned in the previous practicals, we use `summary` to get an idea about what is in the data frame:
```{r}
summary(data1)
```

If we take a closer look at the results, we see that the `dept` column is numeric since `summary` displays information about the minimum, median, mean, max and quantiles.
```
      dept    
 Min.   :  1.00
 1st Qu.: 24.25
 Median : 45.50
 Mean   : 46.88
 3rd Qu.: 66.75
 Max.   :200.00
```

However, for `Region`, we don't see quantiles, etc but we are looking at counts of values, as this column contains factors indicating the particular region (`C`, `E`, `N`, `S` or `W`).  Also note that `NA's: 1` tells us that we have one `NA` which indicates a missing value (Not Available).  We'll discuss later in more detail how these can be dealt with in R.

```
 Region
C   :17
E   :17
N   :17
S   :17
W   :17
NA's: 1
```

We can find the number of variables (columns)
```{r}
length(data1)
```

or by:
```{r}
ncol(data1)
```

Similarly, the number of rows can be found via:
```{r}
nrow(data1)
```

And we can find the dimension of the data frame (i.e. the number of rows and columns) via:
```{r}
dim(data1)
```

The data you have just loaded in is from the Guerry R package, so to get an idea about the variables we need to install the package:
```{r, eval=FALSE}
install.packages("Guerry")
```

Load the library:
```{r}
library(Guerry)
```

and then bring up the help information that relates to this specific data frame which is included in the package:
```{r}
help(Guerry)
```

This data set contains statistics about French cities.  As you can see, there are several different types of columns:

* A few categories: `Region`, `Main_city`
* A few numerical variables: e.g., `Crime_pers`, `Distance`
* A few rank variables: `Donation_clergy`, etc.  These show which city is 1st, 2nd, etc.

### Select a numerical variable and plot a histogram

```{r}	
ggplot(data1, aes(x=Infants)) + geom_histogram(bins=50)
```

### Make a box plot of `Literacy` per city size (`MainCity`) 

```{r}
ggplot(data1, aes(x=MainCity, y=Literacy)) + geom_boxplot()
```

### Managing outliers

In the plot above, we see that the box for the small cities looks strange as it is quite skewed.  We now take a closer look 

First we want to know how many variables are in the small, medium and large cities:

```{r}
a <- table(data1$MainCity)
a
```

This shows that we have 10 observations for small cities.

#### Creating subsets of data frames

Next we want to see the actual data points in the small cities only.  To do this, we'll use the **[dplyr package](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html)**.  The dplyr library takes a very similar approach to what we saw with `ggplot`.  We start off with data in a data frame, and then we perform a series of operations or data transformations which are connected together via the `%>%` symbol which acts as a sort of "pipe" through which data flows.  

In very general terms, with the dplyr library we can create a series of statements that look like:

some data frame `%>%` operation 1 `%>%` operation 2

First we need to install and load the `dplyr` package
```{r, eval=FALSE}
install.packages("dplyr")
library(dplyr)
```

In the following example, we take a subset of the `mtcars` data set.  We first keep a selection of rows by usiing `filter`, and then use `select` to keep certain columns.  

```{r, eval=FALSE}
mtcars %>% 
  filter(hp >= 250 | hp < 100) %>% 
  select(mpg, cyl)
```

In other words:

* `filter(hp >= 250 | hp < 100)` - keep all rows where `hp` is greater than or equal to 250 or is less than 100.  
    * Note that the `|` symbol specifies a logical "or".  This just means that you want to find values matching `hp >= 250` or `hp < 100`
    * The `&` symbol is a logical "and".  You could modify the statement above to use `hp >= 250 & hp < 100`, although this would return no rows since a value can't be both greater than 250 and less than 100.
* `select(mpg, cyl)` - keep only the `mpg` and `cyl` columns.
* The command above is basically of the form: `mtcars` `%>%` "keep these rows" `%>` "keep these columns"

We can also filter on multiple columns by adding commas in the `filter` function.
```{r}
mtcars %>% 
  filter((hp >= 250 | hp < 100), 
         cyl == 4, 
         mpg > 30) %>% 
  select(mpg, cyl)
```

A few notes:

* The `==` symbol in `cyl == 4` means that we check if the value is equal to 4.
* We use parentheses in `(hp >= 250 | hp < 100)` to group these two conditions together, as we want to match either of these conditions.
* In the `filter` function, each of these statements should be set up so that it returns `TRUE` or `FALSE`, as shown in the examples below.  Only rows with `TRUE` for all of the tests specified in `filter` will be returned.

```{r}
# set the value for a variable
hp_val = 300
# is this bigger than or equal to 250?
hp_val >= 250
# is this bigger than or equal to 250 or less than 100?
(hp_val >= 250 | hp_val < 100)
# is it equal to 300?
hp_val == 300
```

Regarding `NA` values:

* If you are doing a numeric comparisons (i.e. `hp >= 250`) using the `filter` function, then `NA` values will be filtered out.  
* If you want to do a numeric comparison and also keep `NA` values, then you need to specify something like `hp >= 250 | is.na(hp)`.  The function `is.na()` will return `TRUE` for any `NA` values.

Now we use dplyr to make subsets of `data1`

```{r}
small_data <- data1 %>% filter(MainCity ==  "1:Sm") %>% select(Crime_prop)
print(small_data)
```

### Filter outliers and make a boxplot of crime vs city size

From above, we can see that there's a large outlier in the small cities, and this would disturb a test like ANOVA. We need to remove this.

We then use the `filter` function with `dplyr` to keep all rows where we don't have a combination of a small city and a `Crime_prop` greater than 15000.

```{r}
data2 = data1 %>% filter(!(MainCity == "1:Sm" & Crime_prop > 15000))
```

You'll notice that the `filter` statement is a bit more complex this time.  Starting from the middle of the statement:

* `&` is again our logical "and" which means that we're looking for situations where the conditions on either side are both true.
* `MainCity == "1:Sm"` and `Crime_prop > 15000` show that we are trying to match rows where the values meet these conditions.
* Most importantly is the `!` symbol on the outside of this clause, which says that we only want to keep rows that **don't** match the conditions specified in the clause `(MainCity == "1:Sm" & Crime_prop > 15000)`
 
Now we can see that the boxplot looks more reasonable.
```{r}
ggplot(data2, aes(x=MainCity, y=Crime_prop)) + geom_boxplot()
```

### Select any row and column by indices

You can also create subsets of data frames by using numeric indices that indicate the row and column numbers.  This technique will work with matrices as well.  Note in the examples below that in some cases you're specifying a sequence of numbers (`5:9` = 5,6,7,8,9), while in other cases, you are specifying a set of numbers (`c(1,5,9)` is just the numbers 1, 5 and 9).  You can also mix in the names of the columns with numeric indices as well.

```{r}
b <- data1[1:3, 5:9]
b
c <- data1[c(1,5,9), 7]
c
d <- data1[c(1,5,9),c("Region", "Infants")]
d
```

Note that both `b` and `d` are data frames, although `c` is a vector of integers.

### Select individual columns
```{r}
x <- data1$Crime_prop
```
or
```{r}
x <- data1$Crime_prop[1:10]  #just select the first 10 rows
```


### Make the whole data frame into a matrix
```{r}
data1_m <- as.matrix(data1)
```

We can get the total number of all elements in the matrix:
```{r}
length(data1_m)
```

Note that we can't access columns via `$` anymore.  In other words, we can't do `data1_m$Crime_prop`

### Make a table of city size vs region

```{r}
tab = table(data1$MainCity, data1$Region)
tab
```

# Dates and Times

Useful resources: 

* [Working with Time Series Data in R ](http://faculty.washington.edu/ezivot/econ424/Working%20with%20Time%20Series%20Data%20in%20R.pdf)
* [R cheat sheet](http://blog.yhat.com/static/pdf/R_date_cheat_sheet.pdf). The columns for `Date` and `POSIXct` are relevant for this practical.  We don't use the `lubridate` library for this example, although it does similar things.  

## Integers to Dates

Dates, not involving times of the day, are natively stored on your computer as integer numbers with 1 Jan 1970  = 0 and 1 corresponding to 1 day. Due to this, you need to specify `origin="1970-01-01"` in the example below.  

For example, the number 365 corresponds January 1, 1971.  To tell R that a number is a date, not just a number you use the command `as.Date`:
```{r}
as.Date(365, origin="1970-01-01")
```
 
## Strings to Dates
R can also convert strings to dates
```{r}
as.Date("1971-01-01")   # always use the order of year, month, day
```

## Vectors of Date Ranges
You can make vectors filled with series of dates using `seq`
```{r}
t = seq(from = as.Date("2000-11-30"), to = as.Date("2000-12-26"), by="1 day")
t
```

`by=` can be e.g, 1 month, 2 years, 5 days, etc...

Now try to make a weekly time vector from 5 June 2005 to 20 August 2006.  You should see:

```{r, echo=FALSE}
t = seq(from = as.Date("2005-06-05"), to = as.Date("2006-08-20"), by="1 week")
t
```

In general, you can treat date & time vectors as normal vectors, which means that you can use them in plots, add and substract them, etc.

# Dates and Times

`POSIXct` does more or less the same as `Date`, but it stores the time variable as numbers of seconds since midnight GMT 1970-01-01.  As a result, this allows us to store data which expresses the time on a specific date.

```{r}
t.str = "2013-12-19 10:17:07"    # default format
t.obj = as.POSIXct(t.str) 
t.obj
```

If you have any other format than default format e.g., if you need to read in data that are not in the default format, then you can give R the format the data are in:

```{r}
t.str1 = "19-12-2013 10:17:07"
t.obj1 = as.POSIXct(t.str1, format="%d-%m-%Y %H:%M:%S")
t.obj1
```

`"%d-%m-%Y %H:%M:%S"` says that we have a time that is specified in the form of day, month and year (separated by `-`) which is then followed by a space and the hours, minutes and seconds (separated by `:`).

To get an overview of all the format types type `help(strptime)`.  Below is a table which summarizes commonly used codes.

| Code | Description              | Example |
|------|--------------------------|---------|
| %a | Abbreviated weekday name | Mon |
| %A | Full weekday name | Monday |
| %b | Abbreviated month name | Jan |
| %B | Full month name | January |
| %c | Date and time. Locale-specific on output, "%a %b %e %H:%M:%S %Y" on input. | |
| %d | Day of the month as decimal number (01–31) | 01 |
| %H | Hours as decimal number (00–23) | 16 |
| %I | Hours as decimal number (01–12) | 08 |
| %j | Day of year as decimal number (001–366) | 234 | 
| %m | Month as decimal number (01–12) | 07 |
| %M | Minute as decimal number (00–59) | 12 | 
| %p | AM/PM indicator | AM |
| %S | Second as integer (00–59) | 35 | 
| %U | Week of the year as decimal number (00–53) using Sunday as the first day 1 of the week (and typically with the first Sunday of the year as day 1 of week 1). The US convention. | |
| %w | Weekday as decimal number (0–6, Sunday is 0). | 1 |
| %W | Week of the year as decimal number (00–53) using Monday as the first day of week (and typically with the first Monday of the year as day 1 of week 1). The UK convention. | | 
| %x | Date. Locale-specific on output, "%y/%m/%d" on input. | | 
| %X | Time. Locale-specific on output, "%H:%M:%S" on input. | |
| %y | Year without century (00–99) | 91 |
| %Y | Year with century | 1991 |
| %z | Signed offset in hours and minutes from UTC, so -0800 is 8 hours behind UTC | |
| %Z | Time zone abbreviation as a character string | PST |

## Changing format of date

You can change the format of the output date using the codes mentioned above.

| Code | Description              | Example |
|------|--------------------------|---------|
| %a | Abbreviated weekday name | Mon |
| %d | Day of the month as decimal number (01–31) | 01 |
| %b | Abbreviated month name | Jan |
| %Y | Year with century | 1991 |

```{r}
t.obj1
format(t.obj1, "%a %d %b. %Y")
```

## Adding and subtracting dates
You can add and subtract POSIXt objects and perform logical operations on them. If you have a vector of POSIXt objects, you can use the `min()`, `max()` and `range()` functions. 

```{r}
t.str2 = "2013-12-19 18:20:07"
t.obj2 = as.POSIXct(t.str2)
```

Subtract two date times:
```{r}
t.obj1 - t.obj2
```

**TODO** add in extra exercises for subtracting & formatting dates based on above examples

## Exercise 1

Load in the data

Exercise: read in Pr_20May1.csv
it contains a time series of monthly temp. from Jan. 1946 to Dec. 2014
Make a vector with the dates corresponding to each data point

```{r, echo=FALSE}
pr = read.csv("/home/cbdavis/Desktop/svn/ChrisDavis/Education/DASM/ComputerPracticals/Pr_20May1.csv")
t = seq(from = as.Date("1946-01-01"), to = as.Date("2014-12-01"), by="1 month")
pr$t = t
library(ggplot2)
ggplot(pr, aes(x=t, y=x)) + geom_line()
```

**TODO** big break - handling real data - create new top level heading

Now we are starting to handle real data, here is an example.  All this goes over what has to be done

* dealing with NA
* dealing with strange/ unwieldy column names
* dealing with dates


1) Real data can have inconvenient column names

How to rename columns in a data set:
e.g. data set: input1


**TODO** put this where the student can download it - put on nestor, also for github

explanation here of how to rename columns

```{r, eval=FALSE}	
#rename column
colnames(input1)[1] <- "x" 	# gives the first column the name "x"
colnames(input1)[2] <- "y"		# gives the second column the name "y"

names(input1)[1] <- "x" 	# gives the first column the name "x"
names(input1)[2] <- "y"		# gives the second column the name "y"
```

## Exercise 2

**TODO** stuff = input1 in notes
Load the data set "Practical4.csv"from nestor and rename the column with the long weird name
See /home/cbdavis/Desktop/svn/ChrisDavis/Education/DASM/ComputerPracticals/Practical_2015_example_chris.pptx

Try to load the file yourselves

```{r, echo=FALSE}
input1 = read.csv("/home/cbdavis/Desktop/svn/ChrisDavis/Education/DASM/ComputerPracticals/Practical4.csv")
```




2) Real data can have missing values

Missing values in R are named NA
But in some data sets the missing values can have any name (e.g.NaN …)
Often they are also indicated by an unrealistic number (e.g., -999)

For R to handle the missing values, you have to rename them as NA, if the are not named like that, R does not recognize them
	
e.g. a data frame called input1 with -999 for missing values

Explain what this comment means
```{r, eval=FALSE}	
input1[input1 == -999] <-NA
```

What does this command do?

`x<-(input1 == -999)`  gives a vector/matrix of the same size as input 1

**TODO** in this case it's a logical matrix
This vector is logical (contains `TRUE`, `FALSE`, and `NA`)

If such a matrix is put into input1 it selects only the fields where x shows `TRUE`

Then it only the fields that are `-999` are replaced by `NA`
	
2) Real data can have missing values

Exercise 2:

before: run summary
```{r}
summary(input1)
```

```{r, echo=FALSE}
input1[input1 == -999] <-NA
```

```

try replacing the -999 in the data set by NA

If you do it correctly, you should see:
```{r}
summary(input1)
```

4) dates and times can be in any format
Then we deal with the dates and times

Exercise 3: 

**TODO** use stuff/input1 data set

* Make time vector of the date in the data set you imported (the `date_start` column)
* make a new vector that formats the date, so that it just shows the month (hint: use the command: `format(date, format = " …" )` covered in the last practical

**TODO** put in the r code for showing the months & the solution

4) sometimes real data sets don't directly contain all the information you want

e.g., you have data covering a year and you are wondering if there is a difference between summer and winter, or between day and night; but you only have a vector with date and time

Make new category variables (e.g. for anova, box plots etc..)

e.g. `input1$y` varies between 0 and 5

```{r, eval=FALSE}
x1 <- c() 	# start with empty vector
x1[input1$y < 1] <- "low"
x1[(input1$y >=1) & (input1$y < 3)] <- "medium"
x1[input1$y>=3] <- "high"
```

`x1` is now a vector of length `input1$y` and consists of values `"low"`, `"medium"`, `"high"`

Exercise 4

Make a vector that correctly assigns the seasons to your data set ( use the meteorological definition of season e.g. winter is dec, jan, feb; spring is mar, apr, may .. 
Look up the logical operators you might need on the internet

**TODO** show what correct output should look like
  
5)combine new data with your data set, or combine several data sets

e.g. second data set input 2 with the same number of rows

**TODO** merge in the season vector with the data frame

```{r, eval=FALSE}
data_new <- cbind(input1, input2) 	#column bind
```

e.g., second data set with new values in the same columns 

e.g., add a new vector x to a data frame

**TODO** you can add vectors to data frames (show)

Exercise 5
add the vector of months and the vector of seasons to your data frome

# Resources
[Data Wrangling with dplyr and tidyr Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) - this shows how you can use `dplyr` for reshaping, combining, grouping, and summarizing data frames.  We will cover `dplyr` in a later practical.

<a href="https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf"><img src="./images/dplyrScreenShot.png" style="height:200px; width:auto"></a>
