---
title: "DASM Practical 2"
author: "Chris Davis"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, message=FALSE}
library(animation)
```


### TODO need to cover

#* Plot distributions
#    * http://www.cookbook-r.com/Graphs/Plotting_distributions_(ggplot2)/
#* confidence intervals
#    * http://docs.ggplot2.org/0.9.3.1/stat_smooth.html
#Also important to get the lower and upper tail - could get weird results based on what they choose

Should cover binomial distribution - this is one of the homework problems.  
"Common distributions" - Example 1 - look at cars @ intersection example.  Show what to put into R

Ask them to do example 2 & 3 in R, based on what I showed them with example 1.
For example 1, plot the distribution, would check to see if answers are reasonable or not.  

Take out combinatorics, permutations, leave in Bayes example with cows.

---

# Background

R contains functions that allow you to easily work with distributions.  The names of these functions follow a standard format - you'll see a "d", "r", "p" or "q" and then the name of the distribution.

The "d", "r", "p" or "q" stands for:

* **d** - density functon for distribution
* **r** - random sample from distribution
* **p** - cumulative distribution
* **q** - quantile function

Below you can see how these letters are combined with the names of the distributions:

<center>
<table width=400><tr><td>
| Distribution<br>Name | Random<br>Samples  | Density<br>Function | Cumulative<br>Distribution | Quantile |
|----------------------+--------------------+---------------------+----------------------------+----------|
| Normal               | `rnorm`            | `dnorm`             | `pnorm`                    | `qnorm`  |
| Poison               | `rpois`            | `dpois`             | `ppois`                    | `qpois`  |
| Binomial             | `rbinom`           | `dbinom`            | `pbinom`                   | `qbinom` |
| Uniform              | `runif`            | `dunif`             | `punif`                    | `qunif`  |
| Student t            | `rt`               | `dt`                | `pt`                       | `qt`     |
| Chi-Squared          | `rchisq`           | `dchisq`            | `pchisq`                   | `qchisq` |
| F                    | `rf`               | `df`                | `pf`                       | `qf`     |
</td></tr></table>
*Source: [Base R Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2016/06/r-cheat-sheet.pdf)*
</center>

Type `?Distributions` into the RStudio Console in order to see documentation on all of the distributions

# Exercises

Load required library and set `stringsAsFactors = FALSE`
```{r}
library(ggplot2)
options(stringsAsFactors = FALSE)
```

## Plot one or two of these distributions and their cumulative distributions 
x vs f(x) 

```{r}
# create a series of x values
xvals = seq(-3, 3, 0.01)

# create a data frame containing values for the density function (sampled at
# each value of xvals) and the cumulative distribution sampled at the same values

dist_data = data.frame(x=xvals, 
                  dist = dnorm(xvals),
                  cumulative_dist = pnorm(xvals))

ggplot() + 
  geom_line(data=dist_data, aes(x=x, y=dist)) + 
  geom_line(data=dist_data, aes(x=x, y=cumulative_dist)) + 
  ylab("Probability") + 
  xlab("X Values")
```

## Find the probabilities 
that x > x0 or x < x0 (with the option lower.tail â€“ FALSE)
```{r}

x0 = 1
# x > x0
pnorm(x0, lower.tail=FALSE)
# x < x0
1 - pnorm(x0, lower.tail=FALSE)

```

## Use the qxxx distributions to find quartiles for different probabilities (also use upper and lower tails) 

```{r}
qnorm(0.80)
qnorm(0.90)
qnorm(0.95)
qnorm(0.99)
```

```{r}
ggplot() + 
  geom_line(data=dist_data, aes(x=x, y=dist), colour="blue") + 
  geom_line(data=dist_data, aes(x=x, y=cumulative_dist), color="red") + 
  ylab("Probability") + 
  xlab("X Values") + 
  geom_vline(xintercept = qnorm(0.5), linetype="dashed") + 
  geom_vline(xintercept = qnorm(0.9), linetype="dashed") +
  geom_vline(xintercept = qnorm(0.95), linetype="dashed") + 
  geom_vline(xintercept = qnorm(0.99), linetype="dashed") + 
  ggtitle("Quantitles for normal distribution at 0.5, 0.9, 0.95, 0.99")
```

## Take random values from a distribution 

```{r}
runif(10)
rnorm(10)
```

Keep this?
```{r animatedHistogram, cache=TRUE, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
x = seq(-3,3,0.01)
density = dnorm(x)
density_df = data.frame(x=x, 
                        y=density)

point_steps = c()
for (i in c(1:5)){
  point_steps = c(point_steps, c(1:10)*10^i)
}

saveGIF({  
  for (number_of_points in point_steps){

  set.seed(12345)
  df = data.frame(vals = rnorm(number_of_points))
  
  p = ggplot() + 
    geom_histogram(data=df, aes(x=vals, y = ..density..), bins=100) + 
    geom_line(data=density_df, aes(x=x, y=density)) + 
    coord_cartesian(xlim=c(-3,3), ylim=c(0,0.45)) + 
    xlab("Values") + ylab("Density") + ggtitle(paste(format(number_of_points, scientific=FALSE), "samples"))

  print(p)
  }
}, interval = 0.1, movie.name = "SampleDistributions.gif", ani.width = 400, ani.height = 300)

```

![Density versus samples](SampleDistributions.gif) 


## Explore an option to selected x random values y times 

(if not done in the previous practicum: let them calculate normal qq plots to explore if a distribution is normal) 

**TODO:** See `help(package="datasets")` for other useful datasets

```{r}

x <- rnorm(100)
qqnorm(x)
qqline(x)

x = iris$Sepal.Length
qqnorm(x)
qqline(x)

x = faithful$waiting
qqnorm(x)
qqline(x)

```

## Let then use the quartile functions to calculate confidence intervals  i.e. give them a data set of values (n<30, but from a normal distribution). 

**TODO** let students repeat this with a new dataset

* let them calculate a qq-normal plot to check if data are normal (**TODO**: done above?)
* Let them calculate confidence intervals for mean and standard deviation. (For this you can put the formula from the lecture at the slides.)



# Big Exercise

* Let them take a random sample n< 30 from a normal distribution
```{r}
vals = rnorm(30, mean=0, sd=1)
```

* let them calculate mean and standard deviation of the distribution compare to the mean and standard deviation of the original distribution 

```{r}
mean_pts = mean(vals)
sd_pts = sd(vals)
```

* Let them calculate the 95% confidence interval of the mean and compare to the original distribution. 
```{r}
qnorm(0.95, mean=mean_pts, sd=sd_pts)
qnorm(0.95, mean=0, sd=1)
```

* For how many students does the confidence interval include the true mean? 

**TODO**: what is meant by this exactly?

---

# OLD 

# Sampling

## Permutations (ordered sample)

### With replacement

Choose k samples from n total objects in $n^{k}$ ways.

### Without replacement

```{r}
n = 5
k = 2
factorial(n) / factorial(n - k)

```

$$ \binom{n}{k} = \frac{n!}{(n-k)!} $$

factorial(n) / factorial(k)*factorial(n - k)


## Combinations (unordered sample)

$$ \binom{n}{k} = \frac{n!}{k!(n-k)!} $$



# Bayes Theorem

$$ P(A|B) = \frac{P(B|A)P(A)}{P(B)} $$ 

* Event A: cow has BSE, $P(A)$=0.01
* Event B: test is positive
* $P(B|A)$ = 0.9 accuracy (= test is positive, if the cow is infected)
* $P(B|A^{c})$ = 0.1 false positives (= test is positive, if the cow is not infected)

What is the chance that B is positive on a randomly chosen cow?
0.01*0.9 + 0.99*0.1 = 0.108


TODO show Bayes with raw data - just a data frame

This gray box represents 100% of the population of cows:

```{r BayesStep1, fig.width=4, fig.height=2.5, echo=FALSE}
ggplot() + 
  geom_rect(data=data.frame(xmin=0, ymin=0, xmax=1, ymax=1), 
            aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), fill="gray") + 
    theme_void() + 
    geom_text(aes(x = 0.5, y = 0.5, label = "All Cows"))
```

We know that 1% of the cow population has BSE:

```{r BayesStep2, fig.width=4, fig.height=2.5, echo=FALSE}
offset_BSE = sqrt(0.01)

xmin_BSE = 0.5 - offset_BSE/2
ymin_BSE = 0.5 - offset_BSE/2
# cover up 0.08964

ggplot() + 
  geom_rect(data=data.frame(xmin=0, ymin=0, xmax=1, ymax=1), 
            aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), fill="gray") + 
  geom_rect(data=data.frame(xmin=xmin_BSE, ymin=ymin_BSE, 
                            xmax=xmin_BSE + offset_BSE, 
                            ymax=ymin_BSE + offset_BSE), 
            aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), color="#0000FF77", fill="#0000FF77") + 
    theme_void() + 
    geom_text(aes(x = 0.5, y = 0.75, label = "All Cows")) +
    geom_text(aes(x = xmin_BSE + offset_BSE/2, y = ymin_BSE + offset_BSE/2, label = "BSE"))
```

But we also know that there are a lot of positive results:

```{r BayesStep3, fig.width=4, fig.height=2.5, echo=FALSE}
offset_Positive = sqrt(0.108)

xmin_Positive = 0.5 - offset_Positive/2
ymin_Positive = 0.5 - offset_Positive/2

ggplot() + 
  geom_rect(data=data.frame(xmin=0, ymin=0, xmax=1, ymax=1), 
            aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), fill="gray") + 
  geom_rect(data=data.frame(xmin=xmin_Positive, ymin=ymin_Positive, 
                            xmax=xmin_Positive + offset_Positive, 
                            ymax=ymin_Positive + offset_Positive), 
            aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), color="#FF000077", fill="#FF000077") + theme_void() + 
    geom_text(aes(x = 0.5, y = 0.75, label = "All Cows")) +
    geom_text(aes(x = 0.5, y = 0.5, label = "Positive Tests"))
```

Just from this, we can see that there are way more positive test results than the number of cows which have BSE, and therefore, getting a positive result may not be a good indication that the cow actually has BSE.

Combining everything together, we get the image shown below.  As you can see, if a cow actually has BSE, then there is a high probability that the test will spot it.  However, since most cows are not infected (99%) and we know that there is a ten percent chance of false positives, this results in a large part of the population that gets positive test results, but actually doesn't have BSE.

A 10% false positive rate (tests positive, no BSE) is actually quite high, when the size of the true positive (tests positive, has BSE) population is much smaller than the false positive rate.

```{r BayesStep4, fig.width=4, fig.height=2.5, echo=FALSE}
offset_BSE = sqrt(0.01)
offset_Positive = sqrt(0.108)

xmin_Positive = 0.5 - offset_Positive/2
ymin_Positive = 0.5 - offset_Positive/2

xmin_BSE = xmin_Positive - (0.1-0.08964)
#ymin_BSE = 0.5 - offset_BSE/2
ymin_BSE = ymin_Positive
# cover up 0.08964

ggplot() + 
  geom_rect(data=data.frame(xmin=0, ymin=0, xmax=1, ymax=1), 
            aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), fill="gray") + 
  geom_rect(data=data.frame(xmin=xmin_BSE, ymin=ymin_BSE, 
                            xmax=xmin_BSE + offset_BSE, 
                            ymax=ymin_BSE + offset_BSE), 
            aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), color="#0000FF77", fill="#0000FF77") + 
  geom_rect(data=data.frame(xmin=xmin_Positive, ymin=ymin_Positive, 
                            xmax=xmin_Positive + offset_Positive, 
                            ymax=ymin_Positive + offset_Positive), 
            aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), color="#FF000077", fill="#FF000077") + theme_void() + 
    geom_text(aes(x = 0.5, y = 0.75, label = "All Cows")) +
    geom_text(aes(x = 0.5, y = 0.5, label = "Positive Tests")) + 
    geom_text(aes(x = xmin_BSE + offset_BSE/2, y = ymin_BSE + offset_BSE/2, label = "BSE"))
```

**TODO** show different falues for positive/false positives

What if we had different values for the probability that the test was accurate (i.e. different values for $P(B|A)$ and $P(B|A^{c})$)?

We still have the same probability of a cow having BSE, so we keep $P(A)$=0.01.

We need to calculate again $P(B)$ which is the probabilitiy of getting a positive result independent of whether the cow has BSE or not.

In R, we represent $P(B|A)$ as the variable `p_B_given_A` and we make a sequence from 0 to 100, which indicates a range of values for the test being 0% accurrate all the way up to 100% accurate at spotting BSE given that the cow actually has BSE.

$$ P(A|B) = \frac{P(B|A)P(A)}{P(B)} $$ 


```{r}
# probability has BSE
p_A = 0.01

# probability tests positive given has BSE (i.e. how accurate the test is if you have BSE)
p_B_given_A = seq(0.8,1,0.005)

# probability that the test is positive (independent of if you have BSE or not)
p_B = (p_A * p_B_given_A) +  # probability that the test is positive if you have BSE
  ((1-p_A) * (1-p_B_given_A))  # probability that the test is positive if you don't have BSE

df = data.frame(p_A = p_A,
                p_B_given_A = p_B_given_A,
                p_B = p_B)

df$p_A_given_B = (df$p_B_given_A * df$p_A) / df$p_B

head(df)

ggplot(df, aes(x=p_B_given_A, y=p_A_given_B)) + 
  geom_point() + 
  xlab("P(B|A) = P(Positive Test Results|Has BSE)
       If the cow has BSE, probability of spotting it with the test") + 
  ylab("P(A|B) = P(Has BSE|Positive Test Results)
       If cow has positive test results, probability that it actually has BSE")

```

This shows something quite interesting - past a certain point, as the test becomes more accurate in spotting cows with BSE, the number of false positives drop at a higher rate than the corresponding increase in accuracy.

If BSE spreads, then your false positives go down, so "accuracy" is partly a function of population size.