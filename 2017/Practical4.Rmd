---
title: "DASM Practical 4"
author: "Chris Davis"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: false
    number_sections: false
---

# {.tabset .tabset-fade .tabset-pills}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Hypothesis Testing

### Getting started

Make sure to load the `tidyverse` library so we can do plotting later on.
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
```

### Example

*This example can be found in slide 27/48 of Lecture 4.*

* From previous research we know that the average life span of a certain species of parrot in their native habitat is 28.0 years. 
* We assume that the life span follows a normal distribution.  
* A researcher studies a sample of 20 parrots in a new habitat and finds an average life span of 30.2 years with a standard deviation of 5.0 years.  
* **Can he say with 95% certainty that they live longer in the new habitat?**

Given the problem statement, we start assigning variables:
```{r}
n = 20       # sample size
s = 5.0      # standard deviation
x_bar = 30.2 # sample average
```

**We have two hypotheses:**

+ $H_{0}: \mu_{0} = 28$ - parrots have the same average lifespan as in their native habitat
+ $H_{a}: \mu_{a} > 28$ - parrots have a longer average lifespan than in their native habitat

```{r}
mu_0 = 28
```

Because we want 95% certainty, we use $\alpha = 0.05$ with a one sided test for the upper tail

**Now we find the rejection region:**

+ Statistic to use: t-statistics (sample < 30, from a normal distribution)
+ Calculate $t_{(1-\alpha)}$ from table : $t_{(1-\alpha)}$ = 1.73 or via R:
```{r}
# we use lower.tail=TRUE since we are looking for the 95% quantile, starting from the lower tail
# qt is the quantile function for the Student t Distribution
t_1_minus_alpha = qt(0.95, df=n-1, lower.tail=TRUE)
t_1_minus_alpha
```


To visualize this, we can plot the t distribution and add a line indicating the location of $t_{(1-\alpha)}$.  

First we create a data frame, where `x` contains a sequence of values along the x axis, and `y` contains the probability density of the t-test distribution.

```{r}
x = seq(-3,3,0.01)
y = dt(x,df=n-1)    # y is equal to the t-test distribution sampled at values of x

# create data frame to hold x and y values
dist = data.frame(x = x, 
                  y = y) 
```

We want to make a plot that contains three different elements:

* the t-test distribution
* a vertical line at the value of `t_1_minus_alpha`
* a text label showing $t_{1-\alpha}$ at the value of `t_1_minus_alpha`

Below we'll show how to make the plot step by step.  Each of the examples below builds on the previous examples, where we add one of the elements in each step.

First plot the distribution:

```{r}
ggplot(dist, aes(x,y)) + 
  geom_line()
```

Same plot as above, but add a vertical dashed line (`geom_vline`) at the location of `t_1_minus_alpha`

```{r}
ggplot(dist, aes(x,y)) + 
  geom_line() +             # this plots the distribution as a line
  geom_vline(xintercept = t_1_minus_alpha,   # plot a vertical line at t_1_minus_alpha
             linetype="dashed")              # make this a dashed line
```

Same plot as the previous one, but now add a label at the x value of `t_1_minus_alpha`, with a `y` value of 0.35.  You can adjust the `y` value to move the label up and down on the plot.

```{r}
ggplot(dist, aes(x,y)) + 
  geom_line() +             # this plots the distribution
  geom_vline(xintercept = t_1_minus_alpha,   # plot a vertical line at t_1_minus_alpha
             linetype="dashed") +            # make this a dashed line
    annotate(geom = "label",          # add a label for t_1_minus_alpha.  
                                      # Don't change geom = "label", it needs to be exactly this
             x = t_1_minus_alpha,     # x position for the label
             y = 0.35,                # y position for the label
             label = "t[(1-alpha)]",    # this is the text that will be displayed
             parse = TRUE)
```

**Calculate the t-statistic:** 

Use the formula $t = \frac{\bar{x} - \mu_{0}}{s/\sqrt{n}}$  

```{r}
t = (x_bar - mu_0)/(s/sqrt(n))
t
```

Below we plot what this looks like.  Note that the plotting code is the same as above, except that at the very end we add one more `geom_vline` statement along with another `annotate` statement so that we can visualize where the value of `t` is located.
```{r}
ggplot(dist, aes(x,y)) + 
  # this plots the distribution
  geom_line() +                     
  # plot a vertical line at t_1_minus_alpha
  geom_vline(xintercept = t_1_minus_alpha,   
             linetype="dashed") +            # make this a dashed line
  # add a label for t_1_minus_alpha.  
  annotate(geom = "label",          # Don't change geom = "label", it needs to be exactly this
           x = t_1_minus_alpha,     # x position for the label
           y = 0.35,                # y position for the label
           label = "t[(1-alpha)]",    # this is the text that will be displayed
           parse = TRUE) +          # use parse = TRUE if you're displaying symbols like alpha
  # plot a vertical line at t
  geom_vline(xintercept = t,        
             linetype="dashed") +   # make this a dashed line
  # add a label for the value of t
  annotate(geom = "label",          
           x = t,
           y = 0.35,                
           label = "t",    
           parse = FALSE)           # can set parse = FALSE, just showing a "t", not symbols like alpha
```

Because $t > t_{(1-\alpha)}$ (`r round(t,2)` > `r round(t_1_minus_alpha,2)`), we reject $H_{0}$, the null hypothesis.

**Calculate the p-value:**

```{r}
# pt is the cumulative distribution of the t distribution
p_value = 1 - pt(t, df=n-1)
p_value
```

We can also calculate this by setting `lower.tail=FALSE` and not subtracting the value from one.

```{r}
p_value = pt(t, df=n-1, lower.tail=FALSE)
p_value
```

If we visualize the cumulative distribution (starting from the right side), we can see that `p_value` is the value of the cumulative distribution at the value of `t`

```{r, echo=FALSE}

x = seq(-3,3,0.01)
y = 1-pt(x,df=n-1)    # y is equal to the t-test distribution sampled at values of x

# create data frame to hold x and y values
cumulative_dist = data.frame(x = x, 
                      y = y) 

ggplot(cumulative_dist, aes(x,y)) + 
  geom_line() + 
  geom_vline(xintercept = t_1_minus_alpha,   # plot a vertical line at t_1_minus_alpha
             linetype="dashed") +            # make this a dashed line
  annotate(geom = "label",          # add a label for t_1_minus_alpha.  
                                    # Don't change geom = "label", it needs to be exactly this
           x = t_1_minus_alpha,     # x position for the label
           y = 0.35,                # y position for the label
           label = "t[(1-alpha)]",    # this is the text that will be displayed
           parse = TRUE) + 
  geom_vline(xintercept = t,        # plot a vertical line at t
             linetype="dashed") +   # make this a dashed line
  annotate(geom = "label",          # add a label for the value of t
           x = t,
           y = 0.35,                
           label = "t",    
           parse = FALSE) + 
  geom_hline(yintercept = p_value, 
             linetype="dashed") + 
  annotate(geom = "label",
           x = 0.3,
           y = p_value,
           label = "p value", 
           parse = FALSE) + 
  geom_point(data=NULL, aes(x=t, y=p_value), colour="red", size=3)


```

### Exercise

Now you should perform a 2-tailed test on your own.  Can you conclude that the lifetimes are different?

We have two hypotheses: 

* $H_{0}: \mu_{0} = 28$
* $H_{a}: \mu_{a} \neq 28$

You should be able to create the following:
```{r, echo=FALSE}
# tails are now alpha/2
t_1_minus_alpha_div_2 = qt(1 - (0.05/2), df=n-1, lower.tail=TRUE)
```

The value for $t_{(1-\alpha/2)}$ should be:

```{r}
t_1_minus_alpha_div_2
```

You should be able to create a plot like the following.  
```{r, echo=FALSE}
# generate a sequence from -3 to 3 in steps of 0.01
x = seq(-3,3,0.01)
left_tail_x = seq(-3,-t_1_minus_alpha_div_2,0.01)
right_tail_x = seq(t_1_minus_alpha_div_2, 3, 0.01)

# create data frame to hold x and y values
dist = data.frame(x=x, 
                  y = dt(x, df=n-1)) # y is equal to the t-test distribution sampled at values of x

# plot the t-test distribution 
# and show the location of t and t_1_minus_alpha_div_2

ggplot(dist, aes(x,y)) + geom_line() + 
  # show line and text annotation for t
  geom_vline(xintercept = t, linetype="dashed") + 
  annotate("label", x=t, y=0.2, label="t") + 
  # show line and text annotation for t_1_minus_alpha_div_2
  geom_vline(xintercept = t_1_minus_alpha_div_2, linetype="dashed") + 
  annotate("label", x=t_1_minus_alpha_div_2, y=0.25, label="t[(1-alpha/2)]", parse=TRUE) + 
  geom_vline(xintercept = -t_1_minus_alpha_div_2, linetype="dashed") + 
  annotate("label", x = -t_1_minus_alpha_div_2, y=0.25, label="t[(alpha/2)]", parse=TRUE)

# critical region will be different and may also have to reject it.
```

## One sample t-test

### Example

*This example can be found in Lecture 4*, and we will use in throughout this practical.

Do marijuana smokers score less points on short term memory test? A study took two sets of people randomly selected from a population of smokers and non-smokers.  Their scores are on the test are the following:

```{r}
non_smoke = c(18,22,21,17,20,17,23,20,22,21)
smoke = c(16,20,14,21,20,18,13,15,17,21)
```

### Syntax for the `t.test` in R

In order to analyze this data, we will use the `t.test` function.  To find the documentation for the correct syntax, we type in the RStudio console `?t.test` to see all options.  In the help window, you should see something like this: 

```{r, eval=FALSE}
t.test(x, y = NULL,
       alternative = c("two.sided", "less", "greater"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95)
```

#### Setting the `alternative` argument

* Whenever you see something like `alternative = c("two.sided", "less", "greater")` that means that you should **choose only one of the values**
    * The correct syntax for the function would be something like `alternative = "two.sided"`.  
* If you try something like `alternative = c("two.sided", "less")` it won't work. 
    * You'll get an error like `Error in match.arg(alternative) : 'arg' must be of length 1`

### Example problem for `t.test`

One question that we can ask with the t.test is if the marijuana smokers score less than the national average.  For this t-test, we examine the smokers only.  We know that in the general population people on average score 20 on the test.  For our values we use:

* `x` is `smokers`
* our `alternative` is one of the three options `"two.sided"`, `"less"` or `"greater"`
* the null hypothesis is that `mu=20`.
* We leave out these other variables like `paired` and `var.equal` because they belong to the two sample test.  We leave out `y` since that refers to a possible second sample.


The first thing we will try is a two sided t-test.

### Two sided t-test

We will now do a two sided t-test for one sample.

* $H_0: \mu = 20$ - our null hypothesis is that smokers also score 20 on the test.
* $H_a: \mu \neq 20$ - our alternative hypothesis is that they score differently.

Here we do a t-test to see if we can reject the null hypothesis, $H_0$, that the smokers also score 20

Using the `t.test()` function, we do a two-sided test as follows:

```{r}
res = t.test(smoke, alternative = "two.sided", mu=20, conf.level = 0.95)
print(res)
```

As you can see, if we print out the results of the t-test, it shows a lot of information.  If we want to simply get the value for the t-statistic, we can just use `res$statistic`:
```{r}
res$statistic
```

You can see which other variables are available by typing `res$` and then typing on the Tab key.  This will bring up a menu showing what is available.

The results we just found can be visualized in the plot below.

* Plot a range of values in the t-distribution
* Mark the 95% confidence interval (the region corresponding to $\alpha=0.05$)
* Mark the value for t (`res$statistic`) from above

```{r}
n = length(smoke)    # number of samples

x = seq(-4, 4, 0.1) # sequence from -3 to 3 in increments of 0.1
y = dt(x, df=n-1)   # probability density of the t distribution

df = data.frame(x=x,
                y=y)

alpha = 0.05
t_alpha_div_2 = qt(alpha/2, df = n-1)
t_1_minus_alpha_div_2 = qt(1 - alpha/2, df = n-1)
t = res$statistic

ggplot(df, aes(x,y)) + geom_line() + 
  # vertical line and label for t_alpha_div_2
  geom_vline(xintercept = t_alpha_div_2, linetype = "dashed") + 
  annotate("label", x = t_alpha_div_2, y=0.25, label="t[(alpha/2)]", parse=TRUE) + 
  # vertical line and label for t_1_minus_alpha_div_2
  geom_vline(xintercept = t_1_minus_alpha_div_2, linetype = "dashed") + 
  annotate("label", x = t_1_minus_alpha_div_2, y=0.25, label = "t[(1 - alpha/2)]", parse=TRUE) + 
  # vertical line and label for t (from the t.test function called above)
  geom_vline(xintercept = t, linetype = "dashed") + 
  annotate("label", x = t, y=0.25, label = "t", parse=FALSE)
```

#### Exercise 1

Try a two-sided test for a value of $mu=17$ (you should see the results below).  Also try with different values of $mu$ and see how that changes the results.

```{r, echo=FALSE}
t.test(smoke, alternative = "two.sided", mu=17, conf.level = 0.95)
```

#### Exercise 2

If instead of typing the command `res = t.test(smoke, alternative = "two.sided", mu=17, conf.level = 0.95)`, you just typed `res = t.test(smoke)`, you would get the results below, which doesn't seem to be correct.  

**What are the default values that are being used by `res = t.test(smoke)`, according to the documentation at `?t.test`?**

```{r, echo=FALSE}
t.test(smoke)
```

### One sided t-test

When performing a one-sided t-test, we need to figure out which value for `alternative` that we need to use.  Which one we choose will be based on the values for $\mu$ and the sample mean.

* if sample mean > $\mu$, then use `alternative = greater`
* if sample mean < $\mu$, then use `alternative = less`

To review, our sample mean in this case is 
```{r}
mean(smoke)
```

As an example, let's try a t-test with a value for $\mu$ of 20, where `alternative = "greater"`.  Note that the value we choose for $\mu$ is greater than our sample mean.
```{r}
t.test(smoke, alternative = "greater", mu=20, conf.level = 0.95)
```

What this is telling us is that these are the hypotheses being tested:

* $H_0: \mu = 20$ 
* $H_a: \mu > 20$ - `alternative hypothesis: true mean is greater than 20`

You'll note that we have a negative t value (`t = -2.6769`).  The alternative hypothesis is that the true mean is greater than 20, therefore R calculates the p-value as the probability of t > -2.6769, and this probability is large!

We also see that `p-value = 0.9873`, because we picked the wrong the sidedness of the t-test.  In other words, we can't reject the null hypothesis $H_0$ that $\mu$ is 20 and it looks very unlikely that $\mu$ > 20.  

However, the sample average is actually less than the hypothesized mean ($\mu$).  We've calculated the p-value of the upper side, when what we want is actually the p-value of the lower side.

To reiterate, if you have a sample mean that is lower than your hypothesized mean, you should never do the upper tail test, only do the lower-tail or two-sided test.  The reverse is true if you have a sample mean that is larger than your hypothesis.  Therefore, the two-sided test is a good choice since you can't go wrong in this way, but it's not as powerful as the one-sided test.  As you saw in the previous example, with the one-sided test you got a significant result, but could not reject the null hypothesis with the two-sided test.

#### Exercise

Do the one-sided t-test shown above, except choose the correct option for `alternative`.  

```{r, echo=FALSE}
t.test(smoke, alternative = "greater", mu=20, conf.level = 0.95)
```

Additionally, try different values for `mu` (pick values above and below the sample mean) and `alternative` to see how these change the results.

## Two sample t-test

### Reminder

As mentioned in the lectures, we know that a t-test can be used in these particular cases: 

* If the sample size >~ 30 (distribution does not matter)
* If the sample size <~ 30, only if distribution is normal 

### mean and sd for `smoke` and `non_smoke`

Further below we'll do t-tests that examine the means and the variances of the populations represented by `smoke` and `non_smoke`.  

As a first step, we calculate the sample means for both the `smoke` ($\bar{x}_1$) and `non_smoke` scores ($\bar{x}_2$):

```{r}
x_bar1 = mean(smoke)
x_bar2 = mean(non_smoke)
print(x_bar1)
print(x_bar2)
```

and do the same for the standard deviations:
```{r}
s1 = sd(smoke)
s2 = sd(non_smoke)
print(s1)
print(s2)
```

What we see from this is that both the means and the standard deviations are different.  Already we see that the average score for the non smokers is higher than that for the smokers.

### Two sample t-test - equal or unequal variances

The approach shown here is described in more detail in Lecture 5, Sections 3.1 & 3.2.

Now we want to do a more detailed test where we compare the scores of the smokers to the scores of the non-smokers.

For this t-test, the difference in the means is calculated by ($\bar{x}_1 - \bar{x}_2$), or in other words, the mean of first sample minus the mean of the second sample.

Our null hypothesis will be that there is no difference in the means:

* $H_0: \mu_1 - \mu_2 = 0$


Using different values for `alternative` will give you the following alternative hypotheses.  Make sure to pay attention to the values for $\bar{x}_1$ and $\bar{x}_2$ when picking which alternative to use.

* $H_a: \mu_1 - \mu_2 > 0$ `alternative = "greater"`
    * use this if $\bar{x}_1$ > $\bar{x}_2$
* $H_a: \mu_1 - \mu_2 < 0$ `alternative = "less"`
    * use this if $\bar{x}_1$ < $\bar{x}_2$
* $H_a: \mu_1 - \mu_2 \neq 0$ `alternative = "two.sided"`

Again, note the syntax for the `t.test` function:
```{r, eval=FALSE}
t.test(x, y = NULL,
       alternative = c("two.sided", "less", "greater"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95)
```

#### Setting `var.equal`

Here we are showing how to analyze samples that may have equal or unequal variances.  To specify which of these situations is the case, we need to use the `var.equal` parameter for the `t.test` function.

The main advice is:

* Use `var.equal = TRUE` if both samples have the same variance.  
    * Only use this if you think they come from distributions with the same variance.  
* If you don't know if the samples actual have the same variance, then it's better to use `var.equal = FALSE`.  
    * If the variances are actually the same and you use `var.equal = FALSE`, then your test is a bit less efficient
    * If the variances are actually different and you use `var.equal = TRUE` then you will get not good results.

#### Example

For this example, we do not need to specify a value of `mu`, but you need to specify the second set of data values (i.e. a value for `y` as specified in the syntax above).  Making sure to set `var.equal=TRUE` we get:

```{r}
t.test(smoke, non_smoke, alternative = "two.sided", conf.level = 0.95, var.equal = TRUE)
```

#### Exercise 1 - non-equal variances

Try a two-sided test for the same data, but with the assumption of non-equal variances.  Compare the p-value to that of the same t-test which assumes equal variances.

```{r, echo=FALSE}
t.test(smoke, non_smoke, alternative = "two.sided", conf.level = 0.95, var.equal = FALSE)
```

#### Exercise 2 - one-sided test

Now try a one-sided test, paying attention to which value for `alternative` you should use.  

```{r, echo=FALSE}
t.test(non_smoke, smoke, alternative = "greater", var.equal = FALSE, conf.level = 0.95)
#t.test(non_smoke, smoke, alternative = "less", var.equal = FALSE, conf.level = 0.95)
```

#### Exercise 3 - two sample t-test - paired

Lecture 4, Slide 44 covers in more detail the approach shown here.

The previous unpaired test with the smokers may not give correct results since it doesn't assume the same individuals are included before and after in the samples.  If we didn't carefully pick the people for the `non_smoke` and `smoke` groups, then there may be other variables that would cause their scores to differ.  

Our results would be much more convincing if we could show that people got lower (or higher) scores after smoking.  If we have data about people's scores before and after smoking, then we can use a paired t-test.  To do this, we will have to specify `paired = TRUE` within the `t.test` function.  (Note that `paired = FALSE` by default, and that this is the option that will be used if you do not specify anything.)

Here we have the test values for individuals both before and after smoking.  Note that the locations in the vectors correspond to specific individuals.
```{r}
# score_person_1_before, score_person_2_before, ...
pre_test = c(77, 56, 64, 60, 57, 53, 72, 62, 65, 66) 

# score_person_1_after, score_person_2_after, ...
post_test = c(88, 74, 83, 68, 58, 50, 67, 64 ,74 ,60) 
```

Try a paired t-test on these values, and then a t-test that is not paired.  Note how this gives you different results.  Make sure to consider which values you should use for `alternative` and `var.equal`, based on `pre_test` and `post_test`.

```{r, echo=FALSE}
t.test(pre_test, post_test, alternative = "less", var.equal = FALSE, paired = TRUE, conf.level = 0.95)
t.test(pre_test, post_test, alternative = "less", var.equal = FALSE, conf.level = 0.95)
```

## The test for equality in variance

### Review from lecture

A test of $s$ in two different populations with size $n_1$, $n_2$ involves the following:

1) A confidence level 1-$\alpha$
2) Two independent, random samples of normal distributions
3) Null hypothesis, $H_0$: $s_1 \le s_2$, or $s_1 \ge s_2$, or $s_1 = s_2$
4) Alternative hypothesis, $H_a$: 
    + $s_1 \gt s_2$     (upper tail alternative)
    + $s_1 \lt s_2$     (lower tail alternative)
    + $s_1 \ne s_2$     (two tailed)
5) Test statistic: $F = \frac{{s_{1}}^2}{{s_{2}}^2}$

### Syntax of `var.test`

```{r, eval=FALSE}
var.test(x, y, ratio = 1, 
         alternative = c("two.sided", "less", "greater"),
         conf.level = 0.95, ...)
```

Relevant arguments for this practical:

* `x, y` - numeric vectors of data values
* `ratio`	- the hypothesized ratio of the population variances of x and y.
* `alternative` - a character string specifying the alternative hypothesis, must be one of `"two.sided"` (default), `"greater"` or `"less"`. You can specify just the initial letter.
* `conf.level` - confidence level for the returned confidence interval.

### Example 

Take 100 samples from two normal distributions with different mean, but the same variance.  Will the test recognize that we should not reject the null hypothesis?

```{r}
x <- rnorm(100, mean=0)  # if you donâ€™t specify the variance it is set to 1 by default
y <- rnorm(100, mean=1)
```

F test to compare two variances:

```{r, echo=FALSE}
f_test_results = var.test(x, y, ratio = 1, alternative = "two.sided", conf.level = 0.95)      
```

```{r}
var.test(x, y, ratio = 1, alternative = "two.sided", conf.level = 0.95)      
```

Since our p-value is `r round(f_test_results$p.value, 4)`, we can't reject the null hypothesis that the ratio of the variances is equal to one.

### Exercise 

Test if variance between smokers and non-smokers is the same

```{r, echo=FALSE}
var.test(smoke, non_smoke, ratio = 1, alternative = "two.sided", conf.level = 0.95)
```