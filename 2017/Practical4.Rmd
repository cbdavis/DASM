---
title: "DASM Practical 4"
author: "Chris Davis"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
html_document:
toc: false
number_sections: false
---

# {.tabset .tabset-fade .tabset-pills}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Hypothesis Testing

### Getting started

Make sure to load the `tidyverse` library so we can do plotting later on.
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
```

### Example

*This example can be found in slide 27/48 of Lecture 4.*

From previous research we know that the average life span of a certain species of parrot in their native habitat is 28.0 years. We assume that the life span follows a normal distribution.  A researcher studies a sample of 20 parrots in a new habitat and finds an average life span of 30.2 years with a standard deviation of 5.0 years.  *Can he say with 95% certainty that they live longer in the new habitat?*

Given the problem statement, we start assigning variables:
```{r}
n = 20       # sample size
s = 5.0      # standard deviation
x_bar = 30.2 # sample average
```

1. We have two hypotheses: 
+ $H_{0}: \mu_{0} = 28$
+ $H_{a}: \mu_{a} > 28$
```{r}
mu_0 = 28
```
2. Because we want 95% certainty, we use $\alpha = 0.05$ with a one sided test for the upper tail
3. Find rejection region
+ Statistic to use: t-statistics (sample < 30, from a normal distribution)
+ Calculate $t_{(1-\alpha)}$ from table : $t_{(1-\alpha)}$ = 1.73 or via R:
```{r}
# we use lower.tail=TRUE since we are looking for the 95% quantile, starting from the lower tail
# qt is the quantile function for the Student t Distribution
t_1_minus_alpha = qt(0.95, df=n-1, lower.tail=TRUE)
t_1_minus_alpha
```
+ Calculate the t-statistic: $t = \frac{\bar{x} - \mu_{0}}{s/\sqrt{n}}$  
```{r}
t = (x_bar - mu_0)/(s/sqrt(n))
t
```
4. Because $t > t_{(1-\alpha)}$ (`r t` > `r t_1_minus_alpha`) we reject $H_{0}$, the null hypothesis.
5. Calculate the p-value: 

```{r}
# pt is the cumulative distribution of the t distribution
p_value = 1 - pt(t, df=n-1)
p_value
```

We can also calculate this by setting `lower.tail=FALSE` and not subtracting the value from one.

```{r}
p_value = pt(t, df=n-1, lower.tail=FALSE)
p_value
```

### Exercise

Plot the t distribution and add vertical lines to indicate where your t-values are and where the rejection regions start.

Hint: to add lines with text, you can use the add statements such as the following when creating a plot:
```{r, eval=FALSE}
+ geom_vline(xintercept = t, linetype="dashed") # add a vertical dashed line at x=t
+ annotate("label", x=t, y=0.3, label="put your text here") # add a label at the stated x and y coordinates
```

```{r, echo=FALSE}
# generate a sequence from -3 to 3 in steps of 0.01
x = seq(-3,3,0.01)

# create data frame to hold x and y values
dist = data.frame(x=x, 
                  y = dt(x,df=19)) # y is equal to the t-test distribution sampled at values of x

# plot the t-test distribution 
# and show the location of t and t_1_minus_alpha

ggplot(dist, aes(x,y)) + geom_line() + 
  # show line and text annotation for t
  geom_vline(xintercept = t, linetype="dashed") + 
  annotate("label", x=t, y=0.3, label="t") + 
  # show line and text annotation for t_1_minus_alpha
  geom_vline(xintercept = t_1_minus_alpha, linetype="dashed") + 
  annotate("label", x=t_1_minus_alpha, y=0.35, label="t[1-alpha]", parse=TRUE)

```

### Exercise

Now you should perform a 2-tailed test on your own.  Can you conclude that the lifetimes are different?

We have two hypotheses: 

* $H_{0}: \mu_{0} = 28$
* $H_{a}: \mu_{a} \neq 28$

You should be able to create the following:
```{r, echo=FALSE}
# tails are now alpha/2
t_1_minus_alpha_div_2 = qt(1 - (0.05/2), df=n-1, lower.tail=TRUE)
```

The value for $t_{(1-\alpha/2)}$ should be:

```{r}
t_1_minus_alpha_div_2
```

You should be able to create a plot like the following.  You don't have to create the filled red regions, you can just add the vertical lines.
```{r, echo=FALSE}
# generate a sequence from -3 to 3 in steps of 0.01
x = seq(-3,3,0.01)
left_tail_x = seq(-3,-t_1_minus_alpha_div_2,0.01)
right_tail_x = seq(t_1_minus_alpha_div_2, 3, 0.01)

# create data frame to hold x and y values
dist = data.frame(x=x, 
                  y = dt(x, df=n-1)) # y is equal to the t-test distribution sampled at values of x

# plot the t-test distribution 
# and show the location of t and t_1_minus_alpha_div_2

ggplot(dist, aes(x,y)) + geom_line() + 
  # show line and text annotation for t
  geom_vline(xintercept = t, linetype="dashed") + 
  annotate("label", x=t, y=0.2, label="t") + 
  # show line and text annotation for t_1_minus_alpha_div_2
  geom_vline(xintercept = t_1_minus_alpha_div_2, linetype="dashed") + 
  annotate("label", x=t_1_minus_alpha_div_2, y=0.25, label="t[1-alpha/2]", parse=TRUE) + 
  geom_vline(xintercept = -t_1_minus_alpha_div_2, linetype="dashed") + 
  annotate("label", x = -t_1_minus_alpha_div_2, y=0.25, label="t[alpha/2]", parse=TRUE) + 
  geom_polygon(data = data.frame(x = c(left_tail_x, rev(left_tail_x)), 
                                 y = c(dt(left_tail_x, df=n-1), 
                                       rep(0, length(left_tail_x)))), 
               fill="red", alpha=0.5) + 
  geom_polygon(data = data.frame(x = c(right_tail_x, rev(right_tail_x)), 
                                 y = c(dt(right_tail_x, df=n-1), 
                                       rep(0, length(right_tail_x)))), 
               fill="red", alpha=0.5)

# critical region will be different and may also have to reject it.
```



## One sample t-test

*This example can be found in Lecture 4*, and we will use in throughout this section.

Do marijuana smokers score less points on short term memory test? A study took two sets of people randomly selected from a population of smokers and non-smokers.  Their scores are on the test are the following:

```{r}
non_smoke = c(18,22,21,17,20,17,23,20,22,21)
smoke = c(16,20,14,21,20,18,13,15,17,21)
```

### Syntax for the `t.test` in R

In order to analyze this data, we will use the `t.test` function... to use this...

The syntax of the t-test is `t.test`, type in the RStudio console `?t.test` to see all options.  In the help window, you should see something like this: 

```{r, eval=FALSE}
t.test(x, y = NULL,
       alternative = c("two.sided", "less", "greater"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95)
```

Whenever you see something like `alternative = c("two.sided", "less", "greater")` that means that you should choose one of the values and the correct syntax for the function would be something like `alternative = "two.sided"`.  

If you try something like `alternative = c("two.sided", "less")` it won't work and you'll see an error like `Error in match.arg(alternative) : 'arg' must be of length 1`

One question that we can ask with the t.test is if the marijuana smokers score less than the national average.  For this t-test, we examine the smokers only.  We know that in the general population people on average score 20 on the test.  For our values we use:

* `x` is `smokers`
* our `alternative` is one of the three options `"two.sided"`, `"less"` or `"greater"`
* the null hypothesis is that `mu=20`.
* We leave out these other variables like `paired` and `var.equal` because they belong to the two sample test.  We leave out `y` since that refers to a possible second sample.


The first thing we will try is a two sided t-test.

### Two sided t-test

Now we look at the two sided t-test for one sample...

Our null hypothesis is that smokers also score 20 on the test.  Our alternative hypothesis is that they score differently. 

Now we need to do a t-test to see if we can reject the null hypothesis that the smokers also score 20 (or even more)

Now we do a two-sided test using `t.test`.  


```{r}
res = t.test(smoke, alternative = "two.sided", mu=20, conf.level = 0.95)
res
```

We can get the value for the t-statistic like this:
```{r}
res$statistic
```

You can see which other variables are available by typing `res$` and then typing on the Tab key.  This will bring up a menu showing what is available.

(put plots here that show where the numbers come from, use the plot from much further below in this tab)

#### Exercise 1

(two-sided)
(try exactly the same thing, but with a different hypothesis to see what happens when you adjust value for mu)

#### Exercise 2

use the default values for two-sided, don't specify mu=, just have to put things in the correct order based on the function specification

### One sided t-test

* if mu > sample mean, then use alternative greater when one-sided
* if mu < sample mean, then use alternative lesser when one-sided


```{r}
t.test(smoke, alternative = "greater", mu=20, conf.level = 0.95)
```

The p-value is 0.9873 since you confused the sidedness of the t-test.  The sample average is actually less than the hypothesized mean.  This calculates the p-value of the upper side.

Note the negative t value.  The alternative hypothesis is that the true mean is greater than 20, therefore R calculates the p-value as the probability of t > -2.6769, and this probability is large!

Now we plot the t-distribution with alpha = 0.05 and degrees of freedom is 9 (since n-1).  For the upper tail t-test, your t value is negative something since it's on the left side of the distribution.  The upper tail t-test calculates the probability of greater than this t-value

```{r, echo=TRUE}
x = seq(-3,3,0.01)
n = 10
dist = data.frame(x=x, 
                  y = dt(x, df=n-1)) # y is equal to the t-test distribution sampled at values of x

t_1_minus_alpha = qt(1 - (0.05), df=n-1, lower.tail=TRUE)

right_tail_x = seq(t_1_minus_alpha, 3, 0.01)

ggplot(dist, aes(x,y)) + 
  geom_line() + 
  geom_vline(xintercept = res$statistic, linetype="dashed") + 
  annotate("label", x = res$statistic, y=0.25, label="t") + 
  geom_vline(xintercept = t_1_minus_alpha, linetype="dashed") + 
  annotate("label", x = t_1_minus_alpha, y=0.25, label="t[1-alpha]", parse=TRUE) + 
  geom_polygon(data = data.frame(x = c(right_tail_x, rev(right_tail_x)), 
                                 y = c(dt(right_tail_x, df=n-1), 
                                       rep(0, length(right_tail_x)))), 
               fill="red", alpha=0.5)

```

If you have a sample mean that is lower than your hypothesized mean, you should never do the upper tail test, only do the lower-tail or two-sided test.  The reverse is true if you have a sample mean that is larger than your hypothesis.  Therefore, the two-sided test is a good choice since you can't go wrong in this way, but it's not as powerful as the one-sided test.  As you saw in the previous example, with the one-sided test you got a significant result, but could not reject the null hypothesis with the two-sided test.


#### Exercise
play around with different alternatives and see what you get (don't do two sided here)  Now try on your own a one-sided test if you choose the alternative is greater, even though your sample average is smaller than your hypothesis average.  You should see the following:

try mu which is greater, and mu which is lesser than the sample mean




## Two sample t-test

As mentioned in the lectures, we know that a t-test can be used: 

* If the sample size >~ 30 (distribution does not matter)
* If the sample size <~ 30, only if distribution is normal 

### Example

We now calculate the sample means for both the smoker and non-smoker scores:

```{r}
x_bar1 = mean(non_smoke)
x_bar2 = mean(smoke)
print(x_bar1)
print(x_bar2)
```

and do the same for the standard deviations:
```{r}
s1 = sd(non_smoke)
s2 = sd(smoke)
print(s1)
print(s2)
```

What we see from this is that both the means and the standard deviations are different.  Already we see that the average score for the non smokers is higher than that for the smokers.


### Two sample t-test - equal or unequal variances

**TODO** update lecture references

Instead of comparing this set of smokers to the general population, we want to do a more detailed test (see Lecture 5, section 2.1 & 2.2).  

The null hypothesis goes for the difference in the means, so mu=0 means no difference in the means.  We will still test if `alternative` is greater, lesser or two-sided.  Setting `alternative` to `greater`/`lesser` corresponds to difference in the mean.  

This test then calculates the difference in the means = mean of first sample ($\bar{x}1$) minus the mean of the second sample ($\bar{x}2$).

(add text about if if x_bar_1 > x_bar_2, then use `greater`, otherwise use `lesser` if x_bar_1 < x_bar_2, this is because you're checking if the two means are equal or not)

You need to pay attention to order of x and y, and what `alternative` you choose.

Again, note the syntax for the `t.test` function:
```{r, eval=FALSE}
t.test(x, y = NULL,
       alternative = c("two.sided", "less", "greater"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95)
```

In this example we are dealing with equal or unequal variances, which means that the parameter `var.equal` is now important when using the `t.test` function.

`var.equal` specifies if both samples have the same variance.  You should only use this if you think they come from distributions with the same variance.  If you don't know, then it's better to fill it in as `FALSE`.  If they are the same, then your test is a bit less efficient, but if the variances are different and you fill in `TRUE` then you will get not good results.


For this example, we do not need to specify a value of `mu`, but you need to specify the second set of data values (i.e. `y`).

With `var.equal=TRUE` you should get:
```{r}
t.test(smoke, non_smoke, alternative = "two.sided", conf.level = 0.95, var.equal = TRUE)
```

#### Exercise 1

(students try to put this into a t-test - see what happens with equal and non-equal variances - see what happens to the p-value so see that they're slightly different)

On your own, try with `var.equal=FALSE` and `alternative = "two.sided"` you should get:
```{r, echo=FALSE}
t.test(smoke, non_smoke, alternative = "two.sided", conf.level = 0.95, var.equal = FALSE)
```

#### Exercise 2

Here we try the one-sided tests and figure out which alternative you should take

(only leave code for the correct test, and hide the code, only show the results)

```{r}
t.test(non_smoke, smoke, alternative = "greater", var.equal = FALSE, conf.level = 0.95)
t.test(non_smoke, smoke, alternative = "less", var.equal = FALSE, conf.level = 0.95)
```

### Two sample t-test - paired

In this example, the `paired` parameter for the `t.test` function is important.

The previous unpaired test with the smokers may not give correct results since it doesn't assume the same individuals are included before and after in the samples.

(rewrite, merge sentences together, update lecture reference)

What people often do is have the same people in the test - first people take test before they smoke, and then take the test again after they smoked.  If we assume that these values are measured on the same individual, then we have to choose these paired alternatives (this will be explained more in Lecture 5, section 2.3)

Mention variances TRUE/FALSE and paired TRUE/FALSE are shown below, (this is an example of what is discussed in the sentences above)

```{r}
# test values both before and after smoking:
pre_test = c(77, 56, 64, 60, 57, 53, 72, 62, 65, 66)
post_test = c(88, 74, 83, 68, 58, 50, 67, 64 ,74 ,60)

t.test(pre_test, post_test, alternative = "less", var.equal = FALSE, paired = TRUE, conf.level = 0.95)
t.test(pre_test, post_test, alternative = "less", var.equal = TRUE, conf.level = 0.95)
```

## The test for equality in variance

### Review from lecture

A test of s in two different populations with size  $n_1$, $n_2$ involves the following:

1) A confidence level 1-$\alpha$
2) Two independent, random samples of normal distributions
3) Null hypothesis, $H_0$: $s_1 \le s_2$, or $s_1 \ge s_2$, or $s_1 = s_2$
4) Alternative hypothesis, $H_a$: 
    + $s_1 \gt s_2$     (upper tail alternative)
    + $s_1 \lt s_2$     (lower tail alternative)
    + $s_1 \ne s_2$     (two tailed)
5) Test statistic: $F = \frac{{s_{1}}^2}{{s_{2}}^2}$


### Syntax of `var.test`

```{r, eval=FALSE}
var.test(x, y, ratio = 1, 
         alternative = c("two.sided", "less", "greater"),
         conf.level = 0.95, ...)
```

Relevant arguments for this practical:

* `x, y` - numeric vectors of data values
* `ratio`	- the hypothesized ratio of the population variances of x and y.
* `alternative` - a character string specifying the alternative hypothesis, must be one of "two.sided" (default), "greater" or "less". You can specify just the initial letter.
* `conf.level` - confidence level for the returned confidence interval.

### Example 

Take 100 samples from two normal distributions with different mean, but the same variance.  Will the test recognize that we should not reject the null hypothesis?

```{r}
x <- rnorm(100, mean=0)  # if you donâ€™t specify the variance it is set to 1 by default
y <- rnorm(100, mean=1)
```

F test to compare two variances:
```{r}
var.test(x, y, ratio = 1, alternative = "two.sided", conf.level = 0.95)      
```

### Exercise 

Test if variance between smokers and non-smokers is the same

