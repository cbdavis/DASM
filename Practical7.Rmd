---
title: "Practical 7"
author: "Chris Davis"
date: "October 17, 2016"
output:
  html_document:
    number_sections: yes
    toc: yes
---

**TODO** need consistent format - in some cases use dataframe with time series column.  In others, just use a vector.  This can cause some confusion with the students as some of the functions won't raise an error, but will evaluation all columns in the data frame.

# Load and Install Required Libraries

We need to install the `forecast` package:
```{r, eval=FALSE}
install.packages("forecast")
```

Load the requried libraries for this practical:
```{r, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(forecast)
```


# Creating Time Series Objects

**TODO** explain the `$x` part

As we showed in the previous practical, we can create a sequence of dates (using `seq`), starting at one date with a defined time interval for each step.

```{r}
Tvalues = read.csv("./data/Pr_20May1.csv")
#Tvalues = Tvalues$x 

Tvalues$t = seq(from = as.Date("1946-01-01"), to = as.Date("2014-12-01"), by = "1 month")

# TODO remove this?
t_seq = seq(from = as.Date("1946-01-01"), to = as.Date("2014-12-01"), by = "1 month")

plot(t_seq, Tvalues$x, type = "l")
```

## Exercise

**TODO** is this the right place?  We don't use `ts` here yet

Download the file [Practical7_time_series.txt](https://raw.githubusercontent.com/cbdavis/DASM/master/data/Practical7_time_series.txt) and load it into R.

This contains daily data on the internet traffic from 20. November 2004 to 27. January 2005

Hint: Reading in the text file produces a data frame. For the following analyses it is better to use the data as a simple vector: series <- data$x

Make a vector t of the times corresponding to each data point and plot the time series vs. t. Can you see a seasonality in the data? which period is it?

```{r, echo=FALSE}
series2 = read.csv("./data/Practical7_time_series.txt")
series2$t = seq(from = as.Date("2004-11-19"), to = as.Date("2005-01-26"), by = "1 day")

ggplot(series2, aes(x=t, y=x)) + geom_line()
```

**TODO** take out text below?
There is a weekly seasonality

## Using `ts()`
We can also use the `ts` function to create time series objects.  The relevant syntax is shown below and you can learn more by typing `?ts` into the console.

```{r, eval=FALSE}
ts(data = NA, start = 1, end = numeric(), frequency = 1,
   deltat = 1)
```

Arguments:

* `data` - a vector or matrix of the observed time-series values. 
* `start` - the time of the first observation. Either a single number or a vector of two integers, which specify a natural time unit and a (1-based) number of samples into the time unit. See the examples for the use of the second form.
* `end` - the time of the last observation, specified in the same way as start.
* `frequency` - the number of observations per unit of time.
* `deltat` - the fraction of the sampling period between successive observations; e.g., 1/12 for monthly data. Only one of frequency or deltat should be provided.

To perform the same operation as above, we can also:
```{r}
t_ser <- ts(Tvalues$x, start = c(1946, 1), freq = 12)
plot(t_ser)

t_ser1 <- ts(Tvalues$x, freq = 12)
plot(t_ser1)
```

# Moving-average smoothing

We will now use the `ma` function for moving-average smoothing.

The syntax is:

```{r, eval=FALSE}
ma(x, order, centre=TRUE)
```

Arguments:

* `x` - Univariate time series
* `order` - Order of moving average smoother
* `centre` - If TRUE, then the moving average is centred for even orders.



```{r}
ma5 = ma(Tvalues$x, order = 5)
ma13 = ma(Tvalues$x, order = 13)

Tvalues_with_ma = Tvalues %>% 
  mutate(ma5 = ma(x, order = 5), 
         ma13 = ma(x, order = 13))

#plot(t_seq[1:60], Tvalues[1:60], type = "l")
#lines(t_seq[1:60], ma5[1:60], col = "red")
#lines(t_seq[1:60], ma13[1:60], col = "green")

ggplot(Tvalues_with_ma, aes(x=t)) + 
  geom_line(aes(y=x, color="original data"), size=2) + 
  geom_line(aes(y=ma5, color="ma5")) + 
  geom_line(aes(y=ma13, color="ma13")) + 
  xlim(c(as.Date("1980-01-01"), 
         as.Date("1984-01-01"))) # Just show data from 1980-1984, otherwise the plot is too cluttered

```

## Exercise

Calculate a moving average with order m = 3, 7, and 15 (see lecture) and add it to the plot. Explain the order m means. 

```{r}
series2_with_ma = series2 %>% 
  mutate(ma3 = ma(x, order = 3), 
         ma7 = ma(x, order = 7), 
         ma15 = ma(x, order = 15))

ggplot(series2_with_ma, aes(x=t)) + 
  geom_line(aes(y=x, color="original data"), size=2) + 
  geom_line(aes(y=ma3, color="ma3")) +
  geom_line(aes(y=ma7, color="ma7")) + 
  geom_line(aes(y=ma15, color="ma15"))
  
```

**TODO** take out text below?

m = 3  … red; 3 data points are averaged (1 to the left and right of the data point)
m = 7  … red; 7 data points are averaged (3 to the left and right of the data point)
(this smoothes out the weekly cycle)
m = 15  … red; 15 data points are averaged (7 to the left and right of the data point)


# Lagging time values

**TODO** - do this with dplyr?  should be possible
see dplyr::lag

An easy way to do this is with the `lag` command and `dplyr`

Here we shift the values for `x` in `Tvalues` by three months.  We use the `mutate` function to create a new column named `lag_x` in the data frame.  The `lag` function simply takes as imput a vector and shifts its values by the number specified.  Take for example a vector containing the numbers 1, 2, ..., 10:

```{r}
a = c(1:10)
print(a)
lag(a, 3)
```

As you can see we push all the values over three places and fill in the left side with `NA`.  The values 8, 9 and 10 are discarded since they are pushed out.

Now we create a new data frame with the results of the operation:
```{r}
Tvalues_lag3 = Tvalues %>% mutate(lag_x = lag(x, 3))
```

Looking at the first few rows of the data frame, we can see how `NA` values are inserted at first, with the lagged values starting at row 4:
```{r}
head(Tvalues_lag3)
```

Below we plot the results for several different lag amount.  Instead of creating a new data frame each time, we just pass the results directly to ggplot using `data = Tvalues %>% mutate(lag_x = lag(x, 3))`

```{r}
ggplot(data = Tvalues %>% mutate(lag_x = lag(x, 3)), 
       aes(x=x, y=lag_x)) + 
  geom_point()

# data shifted 6 months
ggplot(data = Tvalues %>% mutate(lag_x = lag(x, 6)), 
       aes(x=x, y=lag_x)) + 
  geom_point()

# data shifted 10 months
ggplot(data = Tvalues %>% mutate(lag_x = lag(x, 10)), 
       aes(x=x, y=lag_x)) + 
  geom_point()

# data shifted 12 months
ggplot(data = Tvalues %>% mutate(lag_x = lag(x, 12)), 
       aes(x=x, y=lag_x)) + 
  geom_point()
```
 
## Exercise

Show the actual correlation (scatter) plot that is used to calculate the ACF at lag 10. 

```{r}
ggplot(data = series2 %>% mutate(lag_x = lag(x, 10)), 
       aes(x = x, y = lag_x)) + 
  geom_point()
```


# Auto- and Cross- Covariance and -Correlation Function Estimation

**TODO** explain acf syntax

```{r, eval=FALSE}
acf(x, lag.max = NULL,
    type = c("correlation", "covariance", "partial"),
    plot = TRUE, na.action = na.fail, demean = TRUE, ...)
```

Arguments:

* `x, y` - a univariate or multivariate (not ccf) numeric time series object or a numeric vector or matrix, or an "acf" object.
* `lag.max` - maximum lag at which to calculate the acf. Default is `10*log10(N/m)` where `N` is the number of observations and m the number of series. Will be automatically limited to one less than the number of observations in the series.
* `type` - character string giving the type of acf to be computed. Allowed values are "correlation" (the default), "covariance" or "partial". Will be partially matched.

```{r}
acf_T = acf(Tvalues,type = "correlation", lag.max = 64)
acf_10 = acf_T$acf[10]
```

## Exercise

Calculate the autocorrelation function (ACF) of the time series and plot it up to lag 30. 

What variability is mainly reflected in the ACF?

```{r, echo=FALSE}
acf.ser2<- acf(series2, type = "correlation", lag.max = 30)
```

The main signal you see in the ACF is the large-scale variation

# Decomposition

## Classical
```{r}
output = decompose(t_ser1)
plot(output)

t_des <- t_ser1 - output$seasonal
plot(t_des)
acf_des <- acf(as.vector(t_des), type = "correlation", lag.max = 64)
```

What happens if we analyze a time series composed of random values:
```{r}
t_ser_random <- ts(runif(20*12), freq = 12)
output = decompose(t_ser1)
plot(output)
```

The `decompose` method does show a seasonal compoment, but it's important to note the scale - the range of random values is much greater than the range of seasonal values

```{r}
df1 = data.frame(random = output$random, 
                 seasonal = output$seasonal)

ggplot() + geom_density(data=df1, aes(x=random, fill="random"), alpha=0.5) + 
  geom_density(data=df1, aes(x=seasonal, fill="seasonal"), alpha=0.5) + xlab("value")
```

Look at the range (min and max values) for the random component and also the seasonal trend:
```{r}  
range(output$random, na.rm=TRUE)
range(output$seasonal, na.rm=TRUE)
```

### Exercise
Decompose the time series using classical decomposition. 

Hint: you need to construct an appropriate time series object first. What frequency do you choose for the time series object? Show the plot and give an interpretation of all elements of the plot. What is the unit of the x-axis?

```{r}
series2.1 <- ts(series2$x, frequency = 7)
dec2 <-decompose(series2.1, type = "additive")
plot(dec2)
```



## Seasonal Decomposition of Time Series by Loess

**TODO** explain syntax

`stl`

```{r, eval=FALSE}
stl(x, s.window, 
    t.window = NULL)
```

Arguments:

* `x` - univariate time series to be decomposed. This should be an object of class "ts" with a frequency greater than one.
* `s.window` - either the character string "periodic" or the span (in lags) of the loess window for seasonal extraction, which should be odd and at least 7, according to Cleveland et al. This has no default.
* `t.window` - the span (in lags) of the loess window for trend extraction, which should be odd. If NULL, the default, nextodd(ceiling((1.5*period) / (1-(1.5/s.window)))), is taken.

**TODO** this is `stats::stl`, typing `?stl` will bring up the help mentioning that stl is also covered in the forecase package

```{r}
output1 = stl(t_ser1, s.window = 15, t.window = 12*15+1)
plot(output1)
t_rem <- output1$time.series[,"remainder"]
acf_rem <-acf(as.vector(t_rem), type = "correlation", lag.max = 64)
```

### Exercise

**TODO** figure out if the exercises fit here.  Check that it's been covered how to do them.

Decompose the time series using stl decomposition. 

Play with the parameters `s.window` and `t.window` until you are satisfied. What do `s.window` and `t.window` represent? Explain the main difference to the classical decomposition. 

```{r}
dec2.1 <- stl(series2.1, s.window = 9, t.window = 13)
plot(dec2.1)
```



Calculate and plot the de-trended time series. 

Reminder for the decomposition produced by a <- stl(…).

```{r}
series2.1.des <-series2$x - dec2.1$time.series[,"trend"]
plot(series2.1.des)
```

Plot and interpret the ACF of the de-trended time series.

```{r}
series2.1.des <-series2$x - dec2.1$time.series[,"trend"]
plot(series2.1.des)
acf(series2.1.des,type = "correlation", lag.max = 30)
```

With the help of the ACF investigate if the remainder still contains information, or if it is random noise. 

```{r}
acf(na.omit(dec2.1$time.series[,"remainder"]), type = "correlation", lag.max = 30)
```

there is n indication of a weak correlation at lag 1 and a weak anticorrelation at lag 2 and 3. This might indicate a causal relationship i.e., that a day with much internet traffic is followed by another day with much internet traffic. But since the correlation is quite weak is might also be due to imperfect decomposition or due to outliers (i.e. the first week with much higher than average weekly cycle. 

This will look slightly different for everyone, depending on how you decomposed the time series

```{r}
plot(dec2.1$time.series[,"remainder"][1:(length(series2)-1)], 
     dec2.1$time.series[,"remainder"][2:length(series2)],
     xlab = "series2(t)", ylab = "series2(t+1)")
```

