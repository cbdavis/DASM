---
title: "Practical 7"
author: "Chris Davis"
date: "October 17, 2016"
output:
  html_document:
    number_sections: yes
    toc: yes
---

**TODO** need to think of student exercises - use a different dataset for the examples?  Could use US power data - issue is that it already contains the time stamp - would have to use as a more complext example.  Maybe use CO2 from Hawaii?  Temperature data from KNMI (Eelde)?

# Load and Install Required Libraries

We need to install the `forecast` package:
```{r, eval=FALSE}
install.packages("forecast")
```

Load the requried libraries for this practical:
```{r, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(forecast)
```


# Creating Time Series Objects

**TODO** explain the `$x` part

As we showed in the previous practical, we can create a sequence of dates (using `seq`), starting at one date with a defined time interval for each step.

```{r}
Tvalues = read.csv("./data/Pr_20May1.csv")
#Tvalues = Tvalues$x 

Tvalues$t = seq(from = as.Date("1946-01-01"), to = as.Date("2014-12-01"), by = "1 month")

# TODO remove this?
t_seq = seq(from = as.Date("1946-01-01"), to = as.Date("2014-12-01"), by = "1 month")

plot(t_seq, Tvalues$x, type = "l")
```

We can also use the `ts` function to create time series objects.  The relevant syntax is shown below and you can learn more by typing `?ts` into the console.

```{r, eval=FALSE}
ts(data = NA, start = 1, end = numeric(), frequency = 1,
   deltat = 1)
```

Arguments:

* `data` - a vector or matrix of the observed time-series values. 
* `start` - the time of the first observation. Either a single number or a vector of two integers, which specify a natural time unit and a (1-based) number of samples into the time unit. See the examples for the use of the second form.
* `end` - the time of the last observation, specified in the same way as start.
* `frequency` - the number of observations per unit of time.
* `deltat` - the fraction of the sampling period between successive observations; e.g., 1/12 for monthly data. Only one of frequency or deltat should be provided.

To perform the same operation as above, we can also:
```{r}
t_ser <- ts(Tvalues$x, start = c(1946, 1), freq = 12)
plot(t_ser)

t_ser1 <- ts(Tvalues$x, freq = 12)
plot(t_ser1)
```

# Moving-average smoothing

We will now use the `ma` function for moving-average smoothing.

The syntax is:

```{r, eval=FALSE}
ma(x, order, centre=TRUE)
```

Arguments:

* `x` - Univariate time series
* `order` - Order of moving average smoother
* `centre` - If TRUE, then the moving average is centred for even orders.



```{r}
ma5 = ma(Tvalues, order = 5)
ma13 = ma(Tvalues, order = 13)

Tvalues_with_ma = Tvalues %>% 
  mutate(ma5 = ma(x, order = 5), 
         ma13 = ma(x, order = 13))

#plot(t_seq[1:60], Tvalues[1:60], type = "l")
#lines(t_seq[1:60], ma5[1:60], col = "red")
#lines(t_seq[1:60], ma13[1:60], col = "green")

ggplot(Tvalues_with_ma, aes(x=t)) + 
  geom_line(aes(y=x, color="original data"), size=2) + 
  geom_line(aes(y=ma5, color="ma5")) + 
  geom_line(aes(y=ma13, color="ma13")) + 
  xlim(c(as.Date("1980-01-01"), 
         as.Date("1984-01-01"))) # Just show data from 1980-1984, otherwise the plot is too cluttered

```

# Lagging time values

**TODO** - do this with dplyr?  should be possible
see dplyr::lag

An easy way to do this is with the `lag` command and `dplyr`

Here we shift the values for `x` in `Tvalues` by three months.  We use the `mutate` function to create a new column named `lag_x` in the data frame.  The `lag` function simply takes as imput a vector and shifts its values by the number specified.  Take for example a vector containing the numbers 1, 2, ..., 10:

```{r}
a = c(1:10)
print(a)
lag(a, 3)
```

As you can see we push all the values over three places and fill in the left side with `NA`.  The values 8, 9 and 10 are discarded.

Now we create a new data frame with the results of the operation:
```{r}
Tvalues_lag3 = Tvalues %>% mutate(lag_x = lag(x, 3))
```

Looking at the first few rows of the data frame, we can see how `NA` values are inserted at first, with the lagged values starting at row 4:
```{r}
head(Tvalues_lag3)
```

Below we plot the results for several different lag amount.  Instead of creating a new data frame each time, we just pass the results directly to ggplot using `data = Tvalues %>% mutate(lag_x = lag(x, 3))`

```{r}
ggplot(data = Tvalues %>% mutate(lag_x = lag(x, 3)), 
       aes(x=x, y=lag_x)) + 
  geom_point()

# data shifted 6 months
ggplot(data = Tvalues %>% mutate(lag_x = lag(x, 6)), 
       aes(x=x, y=lag_x)) + 
  geom_point()

# data shifted 10 months
ggplot(data = Tvalues %>% mutate(lag_x = lag(x, 10)), 
       aes(x=x, y=lag_x)) + 
  geom_point()

# data shifted 12 months
ggplot(data = Tvalues %>% mutate(lag_x = lag(x, 12)), 
       aes(x=x, y=lag_x)) + 
  geom_point()
```
 
Auto- and Cross- Covariance and -Correlation Function Estimation

**TODO** explain acf syntax

```{r, eval=FALSE}
acf(x, lag.max = NULL,
    type = c("correlation", "covariance", "partial"),
    plot = TRUE, na.action = na.fail, demean = TRUE, ...)
```

Arguments:

* `x, y` - a univariate or multivariate (not ccf) numeric time series object or a numeric vector or matrix, or an "acf" object.
* `lag.max` - maximum lag at which to calculate the acf. Default is `10*log10(N/m)` where `N` is the number of observations and m the number of series. Will be automatically limited to one less than the number of observations in the series.
* `type` - character string giving the type of acf to be computed. Allowed values are "correlation" (the default), "covariance" or "partial". Will be partially matched.

```{r}
acf_T = acf(Tvalues,type = "correlation", lag.max = 64)
acf_10 = acf_T$acf[10]
```

# Decomposition

## Classical
```{r}
output = decompose(t_ser1)
plot(output)

t_des <- t_ser1 - output$seasonal
plot(t_des)
acf_des <- acf(as.vector(t_des), type = "correlation", lag.max = 64)
```

What happens if we analyze a time series composed of random values:
```{r}
t_ser_random <- ts(runif(20*12), freq = 12)
output = decompose(t_ser1)
plot(output)
```

The `decompose` method does show a seasonal compoment, but it's important to note the scale - the range of random values is much greater than the range of seasonal values

```{r}
df1 = data.frame(random = output$random, 
                 seasonal = output$seasonal)

ggplot() + geom_density(data=df1, aes(x=random, fill="random"), alpha=0.5) + 
  geom_density(data=df1, aes(x=seasonal, fill="seasonal"), alpha=0.5) + xlab("value")
```

Look at the range (min and max values) for the random component and also the seasonal trend:
```{r}  
range(output$random, na.rm=TRUE)
range(output$seasonal, na.rm=TRUE)
```

## Seasonal Decomposition of Time Series by Loess

**TODO** explain syntax

`stl`

```{r, eval=FALSE}
stl(x, s.window, 
    t.window = NULL)
```

Arguments:

* `x` - univariate time series to be decomposed. This should be an object of class "ts" with a frequency greater than one.
* `s.window` - either the character string "periodic" or the span (in lags) of the loess window for seasonal extraction, which should be odd and at least 7, according to Cleveland et al. This has no default.
* `t.window` - the span (in lags) of the loess window for trend extraction, which should be odd. If NULL, the default, nextodd(ceiling((1.5*period) / (1-(1.5/s.window)))), is taken.

**TODO** this is `stats::stl`, typing `?stl` will bring up the help mentioning that stl is also covered in the forecase package

```{r}
output1 = stl(t_ser1, s.window = 15, t.window = 12*15+1)
plot(output1)
t_rem <- output1$time.series[,"remainder"]
acf_rem <-acf(as.vector(t_rem), type = "correlation", lag.max = 64)
```